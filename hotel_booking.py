# -*- coding: utf-8 -*-
"""hotel booking.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aT6VpQPINOORkla9sGSsJBs2Lq9DJZRe
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



# Load the dataset

df = pd.read_csv("/content/hotel_bookings.csv")

# Display the first few rows of the dataset
print(df.head())

# Check for missing values
print(df.isnull().sum())

# Remove duplicates
df.drop_duplicates(inplace=True)

# Handle missing values
# For numerical columns, fill missing values with mean
numerical_cols = ['lead_time', 'adults', 'children', 'babies', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'agent', 'company', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'total_of_special_requests']
for col in numerical_cols:
    df[col].fillna(df[col].mean(), inplace=True)

# For categorical columns, fill missing values with mode
categorical_cols = ['meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type', 'reservation_status']
for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Perform EDA
# Summary statistics
print(df.describe())

# Correlation matrix
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Distribution of categorical variables
for col in categorical_cols:
    sns.countplot(x=col, data=df)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.show()

# Distribution of numerical variables
for col in numerical_cols:
    sns.histplot(df[col], bins=20, kde=True)
    plt.title(f'Distribution of {col}')
    plt.show()

# Explore various factors
# Example: booking lead time
sns.histplot(df['lead_time'], bins=30, kde=True)
plt.title('Booking Lead Time Distribution')
plt.xlabel('Lead Time')
plt.ylabel('Frequency')
plt.show()

# Example: seasonality
monthly_bookings = df.groupby('arrival_date_month')['hotel'].count().reset_index()
monthly_bookings = monthly_bookings.sort_values(by='arrival_date_month')
plt.figure(figsize=(10, 6))
sns.barplot(x='arrival_date_month', y='hotel', data=monthly_bookings)
plt.title('Monthly Booking Count')
plt.xlabel('Month')
plt.ylabel('Number of Bookings')
plt.xticks(rotation=45)
plt.show()

# Example: length of stay
sns.histplot(df['stays_in_weekend_nights'] + df['stays_in_week_nights'], bins=20, kde=True)
plt.title('Length of Stay Distribution')
plt.xlabel('Length of Stay (Nights)')
plt.ylabel('Frequency')
plt.show()

# Example: demographics
sns.countplot(x='adults', data=df)
plt.title('Number of Adults Distribution')
plt.xlabel('Number of Adults')
plt.ylabel('Count')
plt.show()

# Example: special requests
sns.countplot(x='total_of_special_requests', data=df)
plt.title('Total Special Requests Distribution')
plt.xlabel('Number of Special Requests')
plt.ylabel('Count')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
# Example: Predicting cancellation using logistic regression
X = df[['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'total_of_special_requests']]
y = df['is_canceled']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions on test data
y_pred = model.predict(X_test)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, precision_recall_curve

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
precision, recall, _ = precision_recall_curve(y_test, y_pred)

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

# Plot Precision-Recall Curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='blue', lw=2)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.show()

# Comparison of Predicted vs. Actual Counts
plt.figure(figsize=(8, 6))
plt.bar(['Actual', 'Predicted'], [sum(y_test), sum(y_pred)], color=['blue', 'green'])
plt.title('Comparison of Actual vs. Predicted Cancellation Counts')
plt.ylabel('Count')
plt.show()

# Feature Importance
coefficients = dict(zip(X.columns, model.coef_[0]))
sorted_coefficients = sorted(coefficients.items(), key=lambda x: abs(x[1]), reverse=True)
print("Feature Importance:")
for feature, coef in sorted_coefficients:
    print(f"{feature}: {coef:.2f}")

# Conclusion
print(f"Accuracy: {accuracy:.2f}")